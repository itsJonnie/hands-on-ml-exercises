{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5uVJ9CZuiy_"
      },
      "source": [
        "# Chapter 3 Classification Exercises:\n",
        "* JONATHAN SHER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab4zgMwhuiy_"
      },
      "source": [
        "### Setup:\n",
        "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCTL9iFquizA"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"classification\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhDZeJ3-uizA"
      },
      "source": [
        "## Exercise 1:\n",
        "\n",
        "Try to build a classifier for the MNIST dataset that achieves over 97% accuracy on the test set. Hint: the KNeighborsClassifier works quite well for this task; you just need to find good hyperparameter values (try a grid search on the weights and n_neighbors hyperparameters).\n",
        "\n",
        "* The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LORsJy6zuizA",
        "outputId": "8c34494a-67da-416d-f445-5badaa7e1957"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import MNIST dataset and do some data exploration\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "mnist.keys()\n",
        "\n",
        "# mnist.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyCOAOW0uizB",
        "outputId": "6c2fc90b-a78e-42e4-dced-abdccb42ed7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving figure some_digit_plot\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "some_digit = X[0]\n",
        "some_digit_image = some_digit.reshape(28, 28)\n",
        "plt.imshow(some_digit_image, cmap=mpl.cm.binary)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "save_fig(\"some_digit_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0Oui8OquizB"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=10000, random_state=42)\n",
        "\n",
        "# Preprocess the Data:\n",
        "# The pixel values in the MNIST dataset range from 0 to 255. We'll normalize them to the range [0, 1].\n",
        "\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# #Step 3: Perform Grid Search for Hyperparameter Tuning\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# # Define the parameter grid\n",
        "# param_grid = {\n",
        "#     'n_neighbors': [3, 5, 7, 9, 11],\n",
        "#     'weights': ['uniform', 'distance']\n",
        "# }\n",
        "\n",
        "# # Initialize the KNeighborsClassifier\n",
        "# knn_clf = KNeighborsClassifier()\n",
        "\n",
        "# # Perform grid search\n",
        "# grid_search = GridSearchCV(knn_clf, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=3)\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# # Print the best parameters and the corresponding accuracy\n",
        "# print(\"Best parameters:\", grid_search.best_params_)\n",
        "# print(\"Best cross-validation accuracy:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3u4Xaa_uizB",
        "outputId": "009ea328-14d0-47ec-caba-2376ffccf827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "[CV 1/3] END ....n_neighbors=3, weights=uniform;, score=0.970 total time=  23.8s\n",
            "[CV 2/3] END ....n_neighbors=3, weights=uniform;, score=0.971 total time=  24.8s\n",
            "[CV 3/3] END ....n_neighbors=3, weights=uniform;, score=0.969 total time=  26.5s\n",
            "[CV 1/3] END ...n_neighbors=3, weights=distance;, score=0.971 total time=  24.9s\n",
            "[CV 2/3] END ...n_neighbors=3, weights=distance;, score=0.973 total time=  25.3s\n",
            "[CV 3/3] END ...n_neighbors=3, weights=distance;, score=0.970 total time=  25.2s\n",
            "[CV 1/3] END ....n_neighbors=4, weights=uniform;, score=0.968 total time=  28.7s\n",
            "[CV 2/3] END ....n_neighbors=4, weights=uniform;, score=0.970 total time=  29.1s\n",
            "[CV 3/3] END ....n_neighbors=4, weights=uniform;, score=0.967 total time=  28.1s\n",
            "[CV 1/3] END ...n_neighbors=4, weights=distance;, score=0.972 total time=  28.3s\n",
            "[CV 2/3] END ...n_neighbors=4, weights=distance;, score=0.974 total time=  28.4s\n",
            "[CV 3/3] END ...n_neighbors=4, weights=distance;, score=0.970 total time=  28.0s\n",
            "[CV 1/3] END ....n_neighbors=5, weights=uniform;, score=0.967 total time=  35.6s\n",
            "[CV 2/3] END ....n_neighbors=5, weights=uniform;, score=0.969 total time=  34.2s\n",
            "[CV 3/3] END ....n_neighbors=5, weights=uniform;, score=0.967 total time=  29.2s\n",
            "[CV 1/3] END ...n_neighbors=5, weights=distance;, score=0.969 total time=  28.8s\n",
            "[CV 2/3] END ...n_neighbors=5, weights=distance;, score=0.971 total time=  29.3s\n",
            "[CV 3/3] END ...n_neighbors=5, weights=distance;, score=0.968 total time=  29.0s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
              "             param_grid=[{'n_neighbors': [3, 4, 5],\n",
              "                          'weights': ['uniform', 'distance']}],\n",
              "             verbose=3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [{'weights': [\"uniform\", \"distance\"], 'n_neighbors': [3, 4, 5]}]\n",
        "\n",
        "# Initialize the KNeighborsClassifier\n",
        "knn_clf = KNeighborsClassifier()\n",
        "\n",
        "# Perform grid search\n",
        "grid_search = GridSearchCV(knn_clf, param_grid, cv=3, verbose=3)\n",
        "grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E60U4puuizB",
        "outputId": "f0b4d10e-332c-4f1e-99f0-9d716ffcd157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'n_neighbors': 4, 'weights': 'distance'}\n",
            "Best cross-validation accuracy: 0.9720000000000001\n"
          ]
        }
      ],
      "source": [
        "# Print the best parameters and the corresponding accuracy\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVeD8tIPuizB"
      },
      "source": [
        "* Evaluate the Best Model on the Test Set\n",
        "* Once we have the best hyperparameters, we can evaluate the model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paCwIp1VuizB",
        "outputId": "2d146737-6441-466a-dbc9-a214ba84ea76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set accuracy: 0.9729\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Get the best model\n",
        "best_knn_clf = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_test_pred = best_knn_clf.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy on the test set\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(\"Test set accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF_rM8gyuizB"
      },
      "source": [
        "Our goal of achieving over 97% accuracy on the test set has been achieved with a test set accuracy of 97.29%"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": false,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": false,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}